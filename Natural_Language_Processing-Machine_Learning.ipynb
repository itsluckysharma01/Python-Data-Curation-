{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cef3f9d",
   "metadata": {},
   "source": [
    "                                                  # Natural Language Processing                                                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba84e34a",
   "metadata": {},
   "source": [
    "### üåê Introduction to Natural Language Processing (NLP) in Machine Learning Using NLTK\n",
    "\n",
    "Natural Language Processing (NLP) is a subfield of Artificial Intelligence (AI) and Machine Learning (ML) that focuses on enabling machines to understand, interpret, and generate human language. It bridges the gap between human communication and computer understanding.\n",
    "\n",
    "---\n",
    "\n",
    "### üîç What is NLP?\n",
    "\n",
    "NLP combines linguistics and computer science to process and analyze large amounts of natural language data. Common tasks include:\n",
    "\n",
    "* **Text classification** (e.g., spam detection)\n",
    "* **Sentiment analysis**\n",
    "* **Named Entity Recognition (NER)**\n",
    "* **Machine translation**\n",
    "* **Speech recognition**\n",
    "* **Text summarization**\n",
    "\n",
    "---\n",
    "\n",
    "### üß† NLP in Machine Learning\n",
    "\n",
    "In ML, NLP is used to train models that can make predictions or extract information from text. The pipeline typically involves:\n",
    "\n",
    "1. **Text Preprocessing**\n",
    "2. **Feature Extraction** (e.g., Bag of Words, TF-IDF)\n",
    "3. **Model Training** (e.g., Naive Bayes, SVM, LSTM)\n",
    "4. **Evaluation and Prediction**\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Introduction to NLTK (Natural Language Toolkit)\n",
    "\n",
    "**NLTK** is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources along with libraries for:\n",
    "\n",
    "* Tokenization\n",
    "* Lemmatization\n",
    "* POS tagging\n",
    "* Parsing\n",
    "* WordNet access\n",
    "\n",
    "Install NLTK:\n",
    "\n",
    "```bash\n",
    "pip install nltk\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ Basic NLP Tasks Using NLTK\n",
    "\n",
    "```python\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "text = \"Natural Language Processing makes it possible for machines to understand human language.\"\n",
    "\n",
    "# Tokenization\n",
    "tokens = word_tokenize(text)\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Stopword Removal\n",
    "filtered = [word for word in tokens if word.lower() not in stopwords.words('english')]\n",
    "print(\"Filtered Tokens:\", filtered)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized = [lemmatizer.lemmatize(word) for word in filtered]\n",
    "print(\"Lemmatized:\", lemmatized)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### üìå Why Use NLTK?\n",
    "\n",
    "* Beginner-friendly\n",
    "* Extensive documentation and corpora\n",
    "* Excellent for prototyping NLP workflows\n",
    "* Good integration with other ML libraries (e.g., Scikit-learn)\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210a3eb5",
   "metadata": {},
   "source": [
    "# **NLTK modules** and their **functionalities**:\n",
    "\n",
    "| **Module**                    | **Functionality**                                  | **Example Functions**                       | **Use Case**                                         |\n",
    "| ----------------------------- | -------------------------------------------------- | ------------------------------------------- | ---------------------------------------------------- |\n",
    "| `nltk.tokenize`               | Splits text into sentences or words (tokenization) | `word_tokenize()`, `sent_tokenize()`        | Preprocessing input text                             |\n",
    "| `nltk.corpus`                 | Access to text corpora and lexical resources       | `stopwords.words()`, `names.words()`        | Working with language datasets                       |\n",
    "| `nltk.stem`                   | Reduces words to their stem/root form              | `PorterStemmer()`, `LancasterStemmer()`     | Normalizing words (e.g., \"running\" ‚Üí \"run\")          |\n",
    "| `nltk.stem.WordNetLemmatizer` | Converts words to their lemma (dictionary form)    | `lemmatize()`                               | Semantic normalization (more accurate than stemming) |\n",
    "| `nltk.probability`            | Support for frequency distributions                | `FreqDist()`                                | Word frequency analysis                              |\n",
    "| `nltk.tag`                    | Assigns POS (Part of Speech) tags to tokens        | `pos_tag()`                                 | Syntax analysis                                      |\n",
    "| `nltk.chunk`                  | Groups tokens into meaningful phrases              | `ne_chunk()`                                | Named Entity Recognition (NER)                       |\n",
    "| `nltk.parse`                  | Syntax parsing of sentences                        | Various parsers                             | Tree-based parsing                                   |\n",
    "| `nltk.classify`               | Text classification using machine learning         | `NaiveBayesClassifier`, `SklearnClassifier` | Sentiment analysis, spam detection                   |\n",
    "| `nltk.translate`              | Tools for machine translation and BLEU scoring     | `bleu_score`                                | Translation evaluation                               |\n",
    "| `nltk.draw`                   | Visualization of parse trees and relationships     | `tree.draw()`, `dispersion_plot()`          | NLP visualizations                                   |\n",
    "| `nltk.metrics`                | Evaluation metrics for NLP models                  | `edit_distance()`, `accuracy()`             | Model evaluation                                     |\n",
    "| `nltk.sentiment`              | Pre-built tools for sentiment analysis             | `SentimentIntensityAnalyzer`                | Polarity scoring (positive/negative)                 |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00d536",
   "metadata": {},
   "source": [
    "# Natural Language Toolkit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00df63f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdf6f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\PANDIT\n",
      "[nltk_data]     JI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import StopWords to this colab file\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "838939ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "engWordsList = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7d28f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n",
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
     ]
    }
   ],
   "source": [
    "print(len(engWordsList))\n",
    "print(engWordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d103d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
