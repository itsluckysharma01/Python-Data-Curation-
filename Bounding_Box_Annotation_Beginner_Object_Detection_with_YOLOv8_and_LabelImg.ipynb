{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54f4d09",
   "metadata": {},
   "source": [
    "# **Bounding Box Annotation Beginner_Object_Detection_with_YOLOv8_and_LabelImg**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498c6bd",
   "metadata": {},
   "source": [
    "**Introduction to Image Annotation**\n",
    "---\n",
    "\n",
    "## 🖼️✨ **What is Image Annotation?**\n",
    "\n",
    "Imagine you're teaching a kid what a \"cat\" looks like. You show them a picture and say:\n",
    "\n",
    "> “This is a cat!” 🐱\n",
    "\n",
    "**Image Annotation** works the same way — but for **machines**.\n",
    "You label or tag **what’s in an image** so that a computer can **learn** from it.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Think of it like this:\n",
    "\n",
    "* You’re the teacher.\n",
    "* The image is the lesson.\n",
    "* The label (annotation) is the explanation.\n",
    "* The machine is the student.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 **Why Do We Annotate Images?**\n",
    "\n",
    "Because machines don’t \"see\" the way humans do.\n",
    "\n",
    "> 📷 To a computer, an image is just a bunch of numbers (pixels).\n",
    "> ✍️ Annotation tells the computer **what** those pixels represent.\n",
    "\n",
    "This helps with tasks like:\n",
    "\n",
    "* ✅ Object detection (e.g. find the dog in a photo)\n",
    "* ✅ Image classification (e.g. \"this is a car\")\n",
    "* ✅ Facial recognition\n",
    "* ✅ Lane detection in self-driving cars\n",
    "* ✅ Medical image analysis\n",
    "\n",
    "---\n",
    "\n",
    "## 🧰 **Types of Image Annotations**\n",
    "\n",
    "| Type                      | Description                              | Example Use                   |\n",
    "| ------------------------- | ---------------------------------------- | ----------------------------- |\n",
    "| 📦 **Bounding Boxes**     | Draw rectangles around objects           | Detect cars, faces            |\n",
    "| 🎯 **Keypoints**          | Mark specific points (e.g. eyes, joints) | Pose estimation               |\n",
    "| 🔲 **Segmentation**       | Label every pixel in an object           | Medical scans, self-driving   |\n",
    "| 📝 **Image-level Labels** | Assign a tag to the whole image          | Dog, Cat, Fruit               |\n",
    "| 🧩 **Polygon Annotation** | Trace the exact shape                    | Irregular objects like leaves |\n",
    "\n",
    "---\n",
    "\n",
    "### 🖌️ Example:\n",
    "\n",
    "You have this image:\n",
    "\n",
    "```\n",
    "[  🐶 Dog playing with 🏀 ball in park  ]\n",
    "```\n",
    "\n",
    "You might annotate it like this:\n",
    "\n",
    "* Draw a bounding box around the **dog**\n",
    "* Draw another box around the **ball**\n",
    "* Label the background as **\"park\"**\n",
    "\n",
    "Now the machine knows:\n",
    "\n",
    "* Object 1 = Dog\n",
    "* Object 2 = Ball\n",
    "* Scene = Park\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Try It Yourself:\n",
    "\n",
    "You can try free tools online to annotate images:\n",
    "\n",
    "* [LabelImg](https://github.com/heartexlabs/labelImg)** (Desktop)\n",
    "* [Makesense.ai](https://www.makesense.ai/)** (Online)\n",
    "* [Roboflow Annotate](https://app.roboflow.com/)** (Online, account needed)\n",
    "* [CVAT (by Intel)](https://cvat.org)\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 In AI Projects:\n",
    "\n",
    "Annotated images are used to **train machine learning models**.\n",
    "These models then predict or detect objects in new, unseen images.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 Where Do Annotations Go?\n",
    "\n",
    "They are saved in files like:\n",
    "\n",
    "* `.xml` (Pascal VOC)\n",
    "* `.json` (COCO)\n",
    "* `.txt` (YOLO)\n",
    "\n",
    "These files describe:\n",
    "\n",
    "* What objects are in the image\n",
    "* Where they are\n",
    "* What label they have\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 Without annotation, computer vision models can’t learn!\n",
    "\n",
    "It’s like giving someone a map with no labels — they’re lost.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5caf882",
   "metadata": {},
   "source": [
    "**Introduction to Bounding Boxes**, especially useful in computer vision and image annotation:\n",
    "\n",
    "---\n",
    "\n",
    "### 🎯 **What is a Bounding Box?**\n",
    "\n",
    "Imagine you’re teaching a computer to recognize objects in images — like a cat, a car, or a person.\n",
    "But how do you tell the computer *where* the object is?\n",
    "\n",
    "That’s where the **bounding box** comes in.\n",
    "📦 It’s like drawing a rectangle **around** the object in an image to say:\n",
    "\n",
    "> \"**Hey! The object is inside this box.**\"\n",
    "\n",
    "---\n",
    "\n",
    "### 🖼️ **Visualize This:**\n",
    "\n",
    "You have this image:\n",
    "\n",
    "```\n",
    "[          🐱 Cat sitting on a couch          ]\n",
    "```\n",
    "\n",
    "Now, draw a box around the cat:\n",
    "\n",
    "```\n",
    "[     ┌─────────────┐       ]\n",
    "[     │     🐱 Cat    │       ]  ← Bounding box!\n",
    "[     └─────────────┘       ]\n",
    "```\n",
    "\n",
    "The box says:\n",
    "\n",
    "* X and Y: where it starts\n",
    "* Width and Height: how big the box is\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **Bounding Box Coordinates**\n",
    "\n",
    "A bounding box is often described by:\n",
    "\n",
    "```python\n",
    "(x_min, y_min, x_max, y_max)\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```python\n",
    "(x, y, width, height)\n",
    "```\n",
    "\n",
    "* `x, y`: Top-left corner of the box\n",
    "* `width, height`: Size of the box\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "Bounding Box = (50, 30, 100, 80)\n",
    "```\n",
    "\n",
    "Means:\n",
    "\n",
    "* Start at (50, 30)\n",
    "* Width = 100 pixels\n",
    "* Height = 80 pixels\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 **Why are Bounding Boxes Important?**\n",
    "\n",
    "Bounding boxes help machines:\n",
    "\n",
    "✅ Detect where objects are\n",
    "✅ Train object detection models\n",
    "✅ Crop objects from images\n",
    "✅ Label datasets (like in YOLO, COCO, Pascal VOC)\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 **Try This Yourself (Manually):**\n",
    "\n",
    "Take any image you have. Draw rectangles around:\n",
    "\n",
    "* A face\n",
    "* A bottle\n",
    "* A vehicle\n",
    "\n",
    "Then write down their coordinates. That's you doing **manual image annotation**!\n",
    "\n",
    "---\n",
    "\n",
    "### 🧰 **Tools That Use Bounding Boxes:**\n",
    "\n",
    "* LabelImg (open-source tool)\n",
    "* CVAT (Computer Vision Annotation Tool)\n",
    "* Roboflow\n",
    "* MakeSense.ai\n",
    "\n",
    "---\n",
    "\n",
    "### 📸 **In Machine Learning Projects:**\n",
    "\n",
    "Bounding boxes are the foundation of many computer vision tasks like:\n",
    "\n",
    "* **Object Detection** (e.g. YOLO, SSD, Faster R-CNN)\n",
    "* **Image Annotation**\n",
    "* **Tracking objects in videos**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a662df8",
   "metadata": {},
   "source": [
    "# **METHODS OF BOUNDING BOX ANNOTATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f59a32c",
   "metadata": {},
   "source": [
    "\n",
    "## ✍️ Methods of Bounding Box Annotation\n",
    "\n",
    "You can annotate images in one of the following ways:\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 1. **How to Annotate using LabelImg (Easiest for Offline Work)**\n",
    "\n",
    "### 🔧 Step-by-Step Setup\n",
    "\n",
    "### ✅ Step 1: Install LabelImg\n",
    "\n",
    "**Windows:**\n",
    "\n",
    "* Download Windows .exe from [releases](https://github.com/heartexlabs/labelImg/releases)\n",
    "  **Linux/macOS/Colab:**\n",
    "\n",
    "```bash\n",
    "# You can try this on Colab for GUI with X11 if needed (advanced)\n",
    "!git clone https://github.com/heartexlabs/labelImg.git\n",
    "!pip install pyqt5 lxml\n",
    "%cd labelImg\n",
    "!make qt5py3\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 2: Open the Tool\n",
    "\n",
    "```bash\n",
    "# Windows:\n",
    "labelImg.exe\n",
    "```\n",
    "\n",
    "### ✅ Step 3: Load Image Folder\n",
    "\n",
    "* Click: `Open Dir` → select the folder containing images (e.g., `bbox_dataset/images/train`)\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 4: Select Save Format\n",
    "\n",
    "* Menu → **PascalVOC** or **YOLO** format (choose YOLO for object detection)\n",
    "* Set annotation folder to `bbox_dataset/labels/train`\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 5: Annotate\n",
    "\n",
    "* Click **\"Create RectBox\"**\n",
    "* Draw box on object → enter class label (e.g., `dog`, `car`)\n",
    "* Save using **Ctrl + S** or click Save icon\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Step 6: Annotations are saved as `.txt` files in YOLO format:\n",
    "\n",
    "Example of `dog.jpg` → `dog.txt`:\n",
    "\n",
    "```\n",
    "0 0.512 0.480 0.210 0.320\n",
    "```\n",
    "\n",
    "This means:\n",
    "\n",
    "```\n",
    "class_id x_center y_center width height  (normalized between 0 and 1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 2. **How to Annotate using Makesense.ai (No Installation Needed)**\n",
    "\n",
    "### 🌐 Website: [https://www.makesense.ai/](https://www.makesense.ai/)\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. Click \"Get Started\"\n",
    "2. Upload your images (can be ZIP or multiple files)\n",
    "3. Choose **Object Detection**\n",
    "4. Add your class labels (e.g., `cat`, `bottle`, etc.)\n",
    "5. Draw bounding boxes\n",
    "6. Export → Choose **YOLO format**\n",
    "\n",
    "It downloads `.txt` files and one file per image.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 3. **How to Manually Annotate Inside Jupyter notebook (Drawing Bounding Boxes)**\n",
    "\n",
    "If you want to draw boxes with mouse inside a notebook using OpenCV (like a mini-LabelImg):\n",
    "\n",
    "This script only works on your local machine (Python installed, OpenCV installed with GUI support):\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "def draw_box(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    clone = img.copy()\n",
    "    bboxes = []\n",
    "\n",
    "    # ✅ Define these variables in the enclosing scope first\n",
    "    x_start, y_start = -1, -1\n",
    "    drawing = False\n",
    "\n",
    "    def draw(event, x, y, flags, param):\n",
    "        nonlocal x_start, y_start, drawing\n",
    "\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            x_start, y_start = x, y\n",
    "            drawing = True\n",
    "\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            drawing = False\n",
    "            x_end, y_end = x, y\n",
    "            cv2.rectangle(img, (x_start, y_start), (x_end, y_end), (0, 255, 0), 2)\n",
    "            bboxes.append((x_start, y_start, x_end, y_end))\n",
    "\n",
    "    cv2.namedWindow(\"Annotation Tool\")\n",
    "    cv2.setMouseCallback(\"Annotation Tool\", draw)\n",
    "\n",
    "    print(\"Press 'q' to finish annotation\")\n",
    "    while True:\n",
    "        cv2.imshow(\"Annotation Tool\", img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return bboxes\n",
    "\n",
    "```\n",
    "\n",
    "> ⚠️ This works only in local Python, not in Colab due to GUI limitations.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 Understanding YOLO Annotation Format (very important!)\n",
    "\n",
    "Each `.txt` file contains **one line per object**:\n",
    "\n",
    "```\n",
    "class_id x_center y_center width height\n",
    "```\n",
    "\n",
    "All values are **normalized** between `0 and 1` w\\.r.t. image dimensions.\n",
    "\n",
    "Example:\n",
    "\n",
    "```plaintext\n",
    "0 0.5 0.5 0.3 0.4\n",
    "```\n",
    "\n",
    "This means:\n",
    "\n",
    "* class\\_id = 0 (e.g., 'cat')\n",
    "* bounding box center is at (50% width, 50% height)\n",
    "* box size is 30% width × 40% height\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠 You can Practice This:\n",
    "\n",
    "* Annotate 5–10 images using [Makesense.ai](https://www.makesense.ai/)\n",
    "* Export in YOLO format\n",
    "* Upload to Colab\n",
    "* Train YOLOv8 on it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feba7c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
